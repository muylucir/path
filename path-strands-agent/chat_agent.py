"""
Chat Agent for PATH Step 2 - ëŒ€í™”í˜• ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë° + ì±„íŒ… ì§€ì›)

ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ê³  í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ Feasibilityë¥¼ í‰ê°€í•˜ëŠ” Agent
"""

from strands import Agent
from typing import Dict, List, Any, AsyncIterator
import json
import re
from prompts import SYSTEM_PROMPT, get_initial_analysis_prompt


class AnalyzerAgent:
    """ì‚¬ìš©ì ì…ë ¥(pain point, input, process, output ë“±)ì„ ë¶„ì„í•˜ëŠ” Agent"""
    
    def __init__(self, model_id: str = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT
        )
    
    def analyze(self, form_data: Dict[str, Any]) -> str:
        """ì´ˆê¸° ë¶„ì„ ìˆ˜í–‰ - ë™ê¸° ë²„ì „"""
        prompt = get_initial_analysis_prompt(form_data)
        result = self.agent(prompt)
        return result.message['content'][0]['text']
    
    async def analyze_stream(self, form_data: Dict[str, Any]) -> AsyncIterator[str]:
        """ì´ˆê¸° ë¶„ì„ ìˆ˜í–‰ - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „"""
        prompt = get_initial_analysis_prompt(form_data)
        
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                yield event["data"]


class ChatAgent:
    """ëŒ€í™”í˜• ë¶„ì„ Agent - ì±„íŒ… ì§€ì›"""
    
    def __init__(self, model_id: str = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT
        )
        self.conversation_history: List[Dict[str, str]] = []
    
    def add_message(self, role: str, content: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.conversation_history.append({"role": role, "content": content})
    
    def get_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.conversation_history
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
    
    def chat(self, user_message: str) -> str:
        """ì±„íŒ… - ë™ê¸° ë²„ì „"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.add_message("user", user_message)
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        history_text = "\n\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in self.conversation_history
        ])
        
        prompt = f"""{history_text}

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬:
1. ì¶”ê°€ ì •ë³´ê°€ ë” í•„ìš”í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ (ìµœëŒ€ 3ê°œ)
2. ì¶©ë¶„í•˜ë©´ "ì´ì œ ìµœì¢… ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ì™„ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”." ì•ˆë‚´

ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."""
        
        result = self.agent(prompt)
        response = result.message['content'][0]['text']
        
        # ì‘ë‹µ ì¶”ê°€
        self.add_message("assistant", response)
        
        return response
    
    async def chat_stream(self, user_message: str) -> AsyncIterator[str]:
        """ì±„íŒ… - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.add_message("user", user_message)
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        history_text = "\n\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in self.conversation_history
        ])
        
        prompt = f"""{history_text}

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬:
1. ì¶”ê°€ ì •ë³´ê°€ ë” í•„ìš”í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ (ìµœëŒ€ 3ê°œ)
2. ì¶©ë¶„í•˜ë©´ "ì´ì œ ìµœì¢… ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ì™„ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”." ì•ˆë‚´

ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."""
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìˆ˜ì§‘
        full_response = ""
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                chunk = event["data"]
                full_response += chunk
                yield chunk
        
        # ì „ì²´ ì‘ë‹µ ì¶”ê°€
        self.add_message("assistant", full_response)


class EvaluatorAgent:
    """ë‹µë³€ ìˆ˜ì§‘ í›„ Feasibility ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” Agent"""
    
    def __init__(self, model_id: str = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT
        )
    
    def evaluate(self, form_data: Dict[str, Any], conversation: List[Dict]) -> Dict[str, Any]:
        """Feasibility í‰ê°€ ìˆ˜í–‰"""
        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in conversation
        ])
        
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Feasibilityë¥¼ í‰ê°€í•˜ì„¸ìš”:

## ì´ˆê¸° ì…ë ¥
**Pain Point**: {form_data.get('painPoint', '')}
**INPUT**: {form_data.get('inputType', form_data.get('input', ''))}
**PROCESS**: {', '.join(form_data.get('processSteps', form_data.get('process', [])))}
**OUTPUT**: {', '.join(form_data.get('outputTypes', form_data.get('output', [])))}
**HUMAN-IN-LOOP**: {form_data.get('humanLoop', form_data.get('humanInLoop', ''))}
**Data Sources**: {json.dumps(form_data.get('dataSources', ''), ensure_ascii=False)}
**Error Tolerance**: {form_data.get('errorTolerance', '')}

## ëŒ€í™” ë‚´ìš©
{conversation_text}

ë‹¤ìŒ 5ê°œ í•­ëª©ì„ í‰ê°€í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

{{
  "data_accessibility": {{"score": 0-10, "reason": "í‰ê°€ ì´ìœ "}},
  "decision_clarity": {{"score": 0-10, "reason": "í‰ê°€ ì´ìœ "}},
  "error_tolerance": {{"score": 0-10, "reason": "í‰ê°€ ì´ìœ "}},
  "latency_requirement": {{"score": 0-10, "reason": "í‰ê°€ ì´ìœ "}},
  "integration_complexity": {{"score": 0-10, "reason": "í‰ê°€ ì´ìœ "}},
  "total_score": 0-50,
  "recommendation": "ì¦‰ì‹œ ì‹œì‘/ì¡°ê±´ë¶€ ì§„í–‰/ê°œì„  í›„ ì¬í‰ê°€/ëŒ€ì•ˆ ëª¨ìƒ‰",
  "patterns": ["ì¶”ì²œ íŒ¨í„´ë“¤"],
  "summary": "ì¢…í•© í‰ê°€ ìš”ì•½"
}}

**ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""
        result = self.agent(prompt)
        response_text = result.message['content'][0]['text']
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            raise ValueError("Failed to extract JSON from evaluation response")


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import asyncio
    
    async def test():
        # ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
        print("ğŸ” ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ í…ŒìŠ¤íŠ¸")
        print("="*80)
        analyzer = AnalyzerAgent()
        async for chunk in analyzer.analyze_stream(form_data):
            print(chunk, end="", flush=True)
        print("\n\nâœ… ì™„ë£Œ!")
    
    asyncio.run(test())

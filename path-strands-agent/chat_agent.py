"""
Chat Agent for PATH Step 2 - ëŒ€í™”í˜• ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë° + ì±„íŒ… ì§€ì›)

ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ê³  í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ Feasibilityë¥¼ í‰ê°€í•˜ëŠ” Agent
"""

from strands import Agent
from typing import Dict, List, Any, AsyncIterator
import json
import re
from strands_tools import file_read
from agentskills import discover_skills, generate_skills_prompt
from strands_utils import strands_utils
from prompts import (
    SYSTEM_PROMPT,
    get_initial_analysis_prompt,
    FEASIBILITY_SYSTEM_PROMPT,
    get_feasibility_evaluation_prompt,
    get_feasibility_reevaluation_prompt,
    PATTERN_ANALYSIS_SYSTEM_PROMPT,
    get_pattern_analysis_prompt
)


class AnalyzerAgent:
    """ì‚¬ìš©ì ì…ë ¥(pain point, input, process, output ë“±)ì„ ë¶„ì„í•˜ëŠ” Agent"""

    def __init__(self, model_id: str = "global.anthropic.claude-opus-4-5-20251101-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT,
            callback_handler=None  # ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
        )
    
    def analyze(self, form_data: Dict[str, Any]) -> str:
        """ì´ˆê¸° ë¶„ì„ ìˆ˜í–‰ - ë™ê¸° ë²„ì „"""
        prompt = get_initial_analysis_prompt(form_data)
        result = self.agent(prompt)
        return result.message['content'][0]['text']
    
    async def analyze_stream(self, form_data: Dict[str, Any]) -> AsyncIterator[str]:
        """ì´ˆê¸° ë¶„ì„ ìˆ˜í–‰ - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „"""
        prompt = get_initial_analysis_prompt(form_data)
        
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                yield event["data"]


class ChatAgent:
    """ëŒ€í™”í˜• ë¶„ì„ Agent - ì±„íŒ… ì§€ì›"""

    def __init__(self, model_id: str = "global.anthropic.claude-opus-4-5-20251101-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT,
            callback_handler=None  # ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
        )
        self.conversation_history: List[Dict[str, str]] = []
    
    def add_message(self, role: str, content: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.conversation_history.append({"role": role, "content": content})
    
    def get_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.conversation_history
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
    
    def chat(self, user_message: str) -> str:
        """ì±„íŒ… - ë™ê¸° ë²„ì „"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.add_message("user", user_message)
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        history_text = "\n\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in self.conversation_history
        ])
        
        prompt = f"""{history_text}

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬:
1. ì¶”ê°€ ì •ë³´ê°€ ë” í•„ìš”í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ (ìµœëŒ€ 3ê°œ)
2. ì¶©ë¶„í•˜ë©´ "ì´ì œ ìµœì¢… ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ì™„ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”." ì•ˆë‚´

ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."""
        
        result = self.agent(prompt)
        response = result.message['content'][0]['text']
        
        # ì‘ë‹µ ì¶”ê°€
        self.add_message("assistant", response)
        
        return response
    
    async def chat_stream(self, user_message: str) -> AsyncIterator[str]:
        """ì±„íŒ… - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.add_message("user", user_message)
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        history_text = "\n\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in self.conversation_history
        ])
        
        prompt = f"""{history_text}

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬:
1. ì¶”ê°€ ì •ë³´ê°€ ë” í•„ìš”í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ (ìµœëŒ€ 3ê°œ)
2. ì¶©ë¶„í•˜ë©´ "ì´ì œ ìµœì¢… ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ì™„ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”." ì•ˆë‚´

ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."""
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìˆ˜ì§‘
        full_response = ""
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                chunk = event["data"]
                full_response += chunk
                yield chunk
        
        # ì „ì²´ ì‘ë‹µ ì¶”ê°€
        self.add_message("assistant", full_response)


class EvaluatorAgent:
    """ë‹µë³€ ìˆ˜ì§‘ í›„ Feasibility ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” Agent"""

    def __init__(self, model_id: str = "global.anthropic.claude-opus-4-5-20251101-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=SYSTEM_PROMPT,
            callback_handler=None  # ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
        )
    
    def evaluate(self, form_data: Dict[str, Any], conversation: List[Dict]) -> Dict[str, Any]:
        """Feasibility í‰ê°€ ìˆ˜í–‰ - PATH ì›¹ì•± í˜•ì‹"""
        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}" 
            for msg in conversation
        ])
        
        prompt = f"""ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ì˜ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤:

{conversation_text}

ì´ì œ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”. ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:

**Universal Agent Design Patterns**:
- **ReAct**: ë‹¨ê³„ì  ì¶”ë¡ (Think) â†’ ë„êµ¬ ì‚¬ìš©(Act) â†’ ê²°ê³¼ ê´€ì°°(Observe) â†’ ë°˜ë³µ
- **Reflection**: ì¶œë ¥ ìƒì„± â†’ í’ˆì§ˆ ê²€í†  â†’ ê°œì„  ë°˜ë³µ (ìê¸° ì„±ì°° ë£¨í”„)
- **Tool Use**: ì™¸ë¶€ ë„êµ¬/APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ì ‘ê·¼, ê³„ì‚°, ì‹œìŠ¤í…œ ì—°ë™
- **Planning**: ë³µì¡í•œ ì‘ì—…ì„ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ìˆœì°¨ ì‹¤í–‰
- **Multi-Agent**: ì „ë¬¸í™”ëœ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ì—­í•  ë¶„ë‹´í•˜ì—¬ í˜‘ì—…
- **Human-in-the-Loop**: Agent ì œì•ˆ â†’ ì‚¬ëŒ ê²€í† /ìŠ¹ì¸ â†’ ì‹¤í–‰

**íŒ¨í„´ ì¡°í•©ë„ ê°€ëŠ¥**: ì˜ˆ) "ReAct + Tool Use", "Planning + Multi-Agent"

{{
  "pain_point": "ì‚¬ìš©ì Pain Point",
  "input_type": "INPUT íƒ€ì…",
  "input_detail": "INPUT ìƒì„¸",
  "process_steps": ["ë‹¨ê³„1: ì„¤ëª…", "ë‹¨ê³„2: ì„¤ëª…", "..."],
  "output_types": ["OUTPUT íƒ€ì…1", "OUTPUT íƒ€ì…2"],
  "output_detail": "OUTPUT ìƒì„¸",
  "human_loop": "None/Review/Exception/Collaborate",
  "pattern": "ReAct/Reflection/Tool Use/Planning/Multi-Agent/Human-in-the-Loop (ì¡°í•© ê°€ëŠ¥)",
  "pattern_reason": "íŒ¨í„´ ì„ íƒ ì´ìœ  (ë¬¸ì œì˜ íŠ¹ì„±ê³¼ íŒ¨í„´ì˜ ì í•©ì„± ì„¤ëª…)",
  "feasibility_breakdown": {{
    "data_access": 0-10,
    "decision_clarity": 0-10,
    "error_tolerance": 0-10,
    "latency": 0-10,
    "integration": 0-10
  }},
  "feasibility_score": 0-50,
  "recommendation": "ì¶”ì²œ ì‚¬í•­",
  "risks": ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2"],
  "next_steps": [
    "Phase 1: í•µì‹¬ ê¸°ëŠ¥ í”„ë¡œí† íƒ€ì… - ì„¤ëª…",
    "Phase 2: ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ - ì„¤ëª…",
    "Phase 3: (ì„ íƒì ) ê°œì„  ë° í™•ì¥ - ì„¤ëª…"
  ]
}}

ì¤‘ìš”: next_stepsëŠ” ì£¼ ë‹¨ìœ„ ê¸°ê°„ì´ ì•„ë‹Œ Phase/ë‹¨ê³„ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        
        system_prompt_for_json = f"""{SYSTEM_PROMPT}

ë‹¹ì‹ ì€ ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""
        
        # Agent ì¬ìƒì„± (JSON ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
        json_agent = Agent(
            model=self.agent.model.config['model_id'],
            system_prompt=system_prompt_for_json,
            callback_handler=None  # ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
        )
        
        result = json_agent(prompt)
        response_text = result.message['content'][0]['text']
        
        # JSON ì¶”ì¶œ
        json_start = response_text.find("{")
        json_end = response_text.rfind("}") + 1
        
        if json_start != -1 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            return json.loads(json_str)
        else:
            raise ValueError("Failed to extract JSON from evaluation response")


class FeasibilityAgent:
    """Step2: Feasibility í‰ê°€ ì „ìš© Agent"""

    def __init__(self, model_id: str = "global.anthropic.claude-opus-4-5-20251101-v1:0"):
        self.agent = Agent(
            model=model_id,
            system_prompt=FEASIBILITY_SYSTEM_PROMPT,
            callback_handler=None  # ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
        )

    def evaluate(self, form_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì´ˆê¸° Feasibility í‰ê°€ ìˆ˜í–‰"""
        prompt = get_feasibility_evaluation_prompt(form_data)
        result = self.agent(prompt)
        response_text = result.message['content'][0]['text']

        # JSON ì¶”ì¶œ
        json_start = response_text.find("{")
        json_end = response_text.rfind("}") + 1

        if json_start != -1 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            return json.loads(json_str)
        else:
            raise ValueError("Failed to extract JSON from feasibility evaluation")

    async def evaluate_stream(self, form_data: Dict[str, Any]) -> AsyncIterator[str]:
        """ì´ˆê¸° Feasibility í‰ê°€ ìˆ˜í–‰ - SSE ìŠ¤íŠ¸ë¦¬ë° (Progress í¬í•¨)"""
        import asyncio

        prompt = get_feasibility_evaluation_prompt(form_data)

        # í‰ê°€ í•­ëª© ë‹¨ê³„
        stages = [
            "ë°ì´í„° ì ‘ê·¼ì„± ë¶„ì„ ì¤‘...",
            "íŒë‹¨ ëª…í™•ì„± ë¶„ì„ ì¤‘...",
            "ì˜¤ë¥˜ í—ˆìš©ë„ ë¶„ì„ ì¤‘...",
            "ì‘ë‹µì†ë„ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘...",
            "ì‹œìŠ¤í…œ ì—°ë™ ë¶„ì„ ì¤‘...",
        ]

        # ì‹œì‘ ì•Œë¦¼
        yield json.dumps({"stage": "ì¤€ë¹„ë„ ì ê²€ ì‹œì‘", "progress": 0}, ensure_ascii=False)

        # LLM í˜¸ì¶œì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        task = asyncio.create_task(asyncio.to_thread(self._evaluate_sync, prompt))

        # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸ (3ì´ˆë§ˆë‹¤)
        progress = 10
        stage_idx = 0
        while not task.done():
            await asyncio.sleep(3)
            if not task.done():
                progress = min(progress + 15, 85)
                stage = stages[stage_idx % len(stages)]
                stage_idx += 1
                yield json.dumps({"stage": stage, "progress": progress}, ensure_ascii=False)

        # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        result = await task

        # ì™„ë£Œ ë° ê²°ê³¼ ì „ì†¡
        yield json.dumps({"stage": "ë¶„ì„ ì™„ë£Œ", "progress": 100}, ensure_ascii=False)
        yield json.dumps({"result": result}, ensure_ascii=False)

    def _evaluate_sync(self, prompt: str) -> Dict[str, Any]:
        """ë™ê¸° í‰ê°€ (ë‚´ë¶€ìš©)"""
        result = self.agent(prompt)
        response_text = result.message['content'][0]['text']

        json_start = response_text.find("{")
        json_end = response_text.rfind("}") + 1

        if json_start != -1 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            return json.loads(json_str)
        else:
            raise ValueError("Failed to extract JSON from feasibility evaluation")

    def reevaluate(self, form_data: Dict[str, Any], previous_evaluation: Dict[str, Any], improvement_plans: Dict[str, str]) -> Dict[str, Any]:
        """ê°œì„ ì•ˆ ë°˜ì˜ ì¬í‰ê°€ ìˆ˜í–‰"""
        prompt = get_feasibility_reevaluation_prompt(form_data, previous_evaluation, improvement_plans)
        result = self.agent(prompt)
        response_text = result.message['content'][0]['text']

        # JSON ì¶”ì¶œ
        json_start = response_text.find("{")
        json_end = response_text.rfind("}") + 1

        if json_start != -1 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            return json.loads(json_str)
        else:
            raise ValueError("Failed to extract JSON from feasibility re-evaluation")


class PatternAnalyzerAgent:
    """Step3: Feasibility ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒ¨í„´ ë¶„ì„í•˜ëŠ” Agent (Skill ì‹œìŠ¤í…œ ì§€ì›)"""

    def __init__(self, model_id: str = "global.anthropic.claude-opus-4-5-20251101-v1:0"):
        # Skill ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        skills = discover_skills("./skills")
        skill_prompt = generate_skills_prompt(skills)
        enhanced_prompt = PATTERN_ANALYSIS_SYSTEM_PROMPT + "\n" + skill_prompt

        self.agent = strands_utils.get_agent(
            system_prompts=enhanced_prompt,
            model_id=model_id,
            max_tokens=16000,
            temperature=0.3,
            tools=[file_read]
        )
        self.conversation_history: List[Dict[str, str]] = []

    def add_message(self, role: str, content: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.conversation_history.append({"role": role, "content": content})

    def get_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.conversation_history

    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []

    def analyze(self, form_data: Dict[str, Any], feasibility: Dict[str, Any]) -> str:
        """Feasibility ê¸°ë°˜ ì´ˆê¸° íŒ¨í„´ ë¶„ì„ - ë™ê¸° ë²„ì „"""
        prompt = get_pattern_analysis_prompt(form_data, feasibility)
        result = self.agent(prompt)
        response = result.message['content'][0]['text']
        self.add_message("assistant", response)
        return response

    async def analyze_stream(self, form_data: Dict[str, Any], feasibility: Dict[str, Any], improvement_plans: Dict[str, str] = None) -> AsyncIterator[str]:
        """Feasibility ê¸°ë°˜ ì´ˆê¸° íŒ¨í„´ ë¶„ì„ - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „"""
        prompt = get_pattern_analysis_prompt(form_data, feasibility, improvement_plans)

        full_response = ""
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                chunk = event["data"]
                full_response += chunk
                yield chunk

        self.add_message("assistant", full_response)

    async def chat_stream(self, user_message: str) -> AsyncIterator[str]:
        """íŒ¨í„´ ê´€ë ¨ ëŒ€í™” - ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ (Skill ì‹œìŠ¤í…œ ì§€ì›)"""
        self.add_message("user", user_message)

        history_text = "\n\n".join([
            f"{msg['role'].upper()}: {msg['content']}"
            for msg in self.conversation_history
        ])

        prompt = f"""{history_text}

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬ íŒ¨í„´ ë¶„ì„ì„ ê³„ì†í•˜ì„¸ìš”.
ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”.
ì¶©ë¶„í•˜ë©´ "íŒ¨í„´ì„ í™•ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'íŒ¨í„´ í™•ì •'ì„ ì…ë ¥í•˜ì„¸ìš”." ì•ˆë‚´í•˜ì„¸ìš”.

**Skill ì‚¬ìš© ì•ˆë‚´**:
- ë‹¤ì´ì–´ê·¸ë¨(í”Œë¡œìš°ì°¨íŠ¸, ë°•ìŠ¤, ì‹œí€€ìŠ¤, í…Œì´ë¸”, íŠ¸ë¦¬ ë“±)ì„ ê·¸ë ¤ì•¼ í•˜ë©´:
  file_readë¡œ "ascii-diagram" ìŠ¤í‚¬ì˜ SKILL.mdë¥¼ ì½ê³  ê°€ì´ë“œë¥¼ ë”°ë¥´ì„¸ìš”.
- ì½”ë“œ ë¸”ë¡(```)ìœ¼ë¡œ ê°ì‹¸ì„œ ê³ ì •í­ í°íŠ¸ë¡œ ì •ë ¬í•˜ì„¸ìš”."""

        full_response = ""
        async for event in self.agent.stream_async(prompt):
            if "data" in event:
                chunk = event["data"]
                full_response += chunk
                yield chunk

        self.add_message("assistant", full_response)

    def finalize(self, form_data: Dict[str, Any], feasibility: Dict[str, Any], improvement_plans: Dict[str, str] = None) -> Dict[str, Any]:
        """íŒ¨í„´ í™•ì • ë° ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„± (ê°œì„ ëœ ì ìˆ˜ í¬í•¨)"""
        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}"
            for msg in self.conversation_history
        ])

        # Feasibility breakdownì„ ë‹¨ìˆœí™”
        breakdown = feasibility.get('feasibility_breakdown', {})
        simple_breakdown = {}
        for key, value in breakdown.items():
            if isinstance(value, dict):
                simple_breakdown[key] = value.get('score', 0)
            else:
                simple_breakdown[key] = value

        # ê°œì„  ë°©ì•ˆ í…ìŠ¤íŠ¸ êµ¬ì„±
        improvement_section = ""
        if improvement_plans:
            plans_with_content = {k: v for k, v in improvement_plans.items() if v and v.strip()}
            if plans_with_content:
                improvement_section = "\n**ì‚¬ìš©ì ê°œì„  ë°©ì•ˆ**:\n"
                for item, plan in plans_with_content.items():
                    improvement_section += f"- {item}: {plan}\n"

        # ê°œì„ ëœ ì ìˆ˜ ê³„ì‚° í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        improved_feasibility_prompt = ""
        if improvement_plans and any(v and v.strip() for v in improvement_plans.values()):
            improved_feasibility_prompt = """
**ê°œì„ ëœ Feasibility ì ìˆ˜ ê³„ì‚° (improved_feasibility)**:
ì‚¬ìš©ìì˜ ê°œì„  ë°©ì•ˆê³¼ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ê°œì„  ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.

ê³„ì‚° ê¸°ì¤€:
1. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ê³„íšë§Œ ì ìˆ˜ì— ë°˜ì˜
2. í•­ëª©ë‹¹ ìµœëŒ€ +3ì  ìƒí–¥ ê°€ëŠ¥
3. ë§‰ì—°í•œ ê³„íšì€ ë°˜ì˜í•˜ì§€ ì•ŠìŒ
4. ì ìˆ˜ëŠ” ìƒí–¥ë§Œ ê°€ëŠ¥ (í•˜í–¥ ë¶ˆê°€)

improved_feasibility í•„ë“œì— ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í¬í•¨:
"improved_feasibility": {
  "score": ê°œì„ í›„ì´ì ,
  "score_change": ì ìˆ˜ë³€í™”ëŸ‰,
  "breakdown": {
    "data_access": {
      "original_score": ì›ë³¸ì ìˆ˜,
      "improved_score": ê°œì„ í›„ì ìˆ˜,
      "improvement_reason": "ì™œ ì ìˆ˜ê°€ ì˜¬ëëŠ”ì§€ êµ¬ì²´ì  ì„¤ëª… (ê°œì„  ë°©ì•ˆì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)"
    },
    "decision_clarity": {...},
    "error_tolerance": {...},
    "latency": {...},
    "integration": {...}
  },
  "summary": "ì „ì²´ ê°œì„  ì ìˆ˜ ìš”ì•½ (1-2ë¬¸ì¥)"
}"""

        prompt = f"""ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ì˜ íŒ¨í„´ ë¶„ì„ ëŒ€í™”ì…ë‹ˆë‹¤:

{conversation_text}

**Feasibility ì •ë³´**:
- ì´ì : {feasibility.get('feasibility_score', 0)}/50
- íŒì •: {feasibility.get('judgment', '')}
{improvement_section}
ì´ì œ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”. ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{improved_feasibility_prompt}
{{
  "pain_point": "ì‚¬ìš©ì Pain Point",
  "input_type": "INPUT íƒ€ì…",
  "input_detail": "INPUT ìƒì„¸",
  "process_steps": ["ë‹¨ê³„1: ì„¤ëª…", "ë‹¨ê³„2: ì„¤ëª…", "..."],
  "output_types": ["OUTPUT íƒ€ì…1", "OUTPUT íƒ€ì…2"],
  "output_detail": "OUTPUT ìƒì„¸",
  "human_loop": "None/Review/Exception/Collaborate",
  "pattern": "ReAct/Reflection/Tool Use/Planning/Multi-Agent/Human-in-the-Loop (ì¡°í•© ê°€ëŠ¥)",
  "pattern_reason": "íŒ¨í„´ ì„ íƒ ì´ìœ  (Feasibilityì™€ ì—°ê³„í•˜ì—¬ ì„¤ëª…)",
  "feasibility_breakdown": {json.dumps(simple_breakdown)},
  "feasibility_score": {feasibility.get('feasibility_score', 0)},
  "improved_feasibility": null,
  "recommendation": "ì¶”ì²œ ì‚¬í•­",
  "risks": ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2"],
  "next_steps": [
    "Phase 1: í•µì‹¬ ê¸°ëŠ¥ í”„ë¡œí† íƒ€ì… - ì„¤ëª…",
    "Phase 2: ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ - ì„¤ëª…",
    "Phase 3: (ì„ íƒì ) ê°œì„  ë° í™•ì¥ - ì„¤ëª…"
  ]
}}

ì¤‘ìš”:
- ì‚¬ìš©ì ê°œì„  ë°©ì•ˆì´ ìˆìœ¼ë©´ improved_feasibilityë¥¼ ê³„ì‚°í•˜ì—¬ í¬í•¨í•˜ì„¸ìš”.
- ê°œì„  ë°©ì•ˆì´ ì—†ê±°ë‚˜ ë°˜ì˜í•  ë‚´ìš©ì´ ì—†ìœ¼ë©´ improved_feasibilityëŠ” nullë¡œ ìœ ì§€í•˜ì„¸ìš”.
- JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        result = self.agent(prompt)
        response_text = result.message['content'][0]['text']

        # JSON ì¶”ì¶œ
        json_start = response_text.find("{")
        json_end = response_text.rfind("}") + 1

        if json_start != -1 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            return json.loads(json_str)
        else:
            raise ValueError("Failed to extract JSON from pattern finalization")


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import asyncio

    async def test():
        # ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
        print("ğŸ” ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ í…ŒìŠ¤íŠ¸")
        print("="*80)
        analyzer = AnalyzerAgent()
        async for chunk in analyzer.analyze_stream(form_data):
            print(chunk, end="", flush=True)
        print("\n\nâœ… ì™„ë£Œ!")

    asyncio.run(test())
